# 爬虫readme
## 1. google_font_spider
> 实验报告一同写在实验报告中，这儿只做使用说明
- google_font_spider 可以爬取google font的差分字库，将文件开始时的main函数的url替换为你想要爬取的字库位置的url即可开始爬取
- 爬取后的文件放置在./result/font目录下，文件名遵循google官网原本的样子，会将源文件的绝对路径改为相对路径，便于网页使用

## 2.小说网站爬取
> 尝试爬取百度的一些内容无果，相比较而言小说的网站的爬取还是比较容易的，小说网站居然基本没有反爬虫

- novel文件夹是一些爬取小说网站的爬虫，因为每一个小说网站的格式均也有所不同,固有很多爬虫多数的爬虫都是基于网页抓取

- 其中以web_spider开头的文件是利用的小说页面的下一页的超链接进行抓取

- 其余的则是利用小说目录页面中所有的网页链接进行抓取

- thread_52biquge.py利用了多线程技术进行抓取，提高了效率，通过对文件的预创建避免了多线程导致的小说章节抓取混乱的问题

> 所有的novel文件夹下的爬虫均可以直接运行，抓取下来的小说会放在/novel文件夹下

![这是抓取到的小说的内容部分](https://gitee.com/widealpha/pic/raw/master/image-20210405194349350.png)
这是抓取的一个小说的样例，共计18万行，10.51mb,用时不到5分钟